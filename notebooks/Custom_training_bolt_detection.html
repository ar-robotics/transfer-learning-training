<!doctype html>
<html class="no-js" lang="en" data-content_root="../">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="viewport" content="width=device-width, initial-scale=1" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="prev" title="Using RoboFlow dataset to detect people using MediaPipe" href="People-detection.html" />

    <!-- Generated with Sphinx 7.3.7 and Furo 2024.05.06 -->
        <title>Using a custom made dataset to detect bolts using Mediapipe - transfer-learning-training 2.0.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?v=387cc868" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?v=36a5483c" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
  <symbol id="svg-sun-with-moon" viewBox="0 0 24 24">
    <title>Auto light/dark, in light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path style="opacity: 50%" d="M 5.411 14.504 C 5.471 14.504 5.532 14.504 5.591 14.504 C 3.639 16.319 4.383 19.569 6.931 20.352 C 7.693 20.586 8.512 20.551 9.25 20.252 C 8.023 23.207 4.056 23.725 2.11 21.184 C 0.166 18.642 1.702 14.949 4.874 14.536 C 5.051 14.512 5.231 14.5 5.411 14.5 L 5.411 14.504 Z"/>
      <line x1="14.5" y1="3.25" x2="14.5" y2="1.25"/>
      <line x1="14.5" y1="15.85" x2="14.5" y2="17.85"/>
      <line x1="10.044" y1="5.094" x2="8.63" y2="3.68"/>
      <line x1="19" y1="14.05" x2="20.414" y2="15.464"/>
      <line x1="8.2" y1="9.55" x2="6.2" y2="9.55"/>
      <line x1="20.8" y1="9.55" x2="22.8" y2="9.55"/>
      <line x1="10.044" y1="14.006" x2="8.63" y2="15.42"/>
      <line x1="19" y1="5.05" x2="20.414" y2="3.636"/>
      <circle cx="14.5" cy="9.55" r="3.6"/>
    </svg>
  </symbol>
  <symbol id="svg-moon-with-sun" viewBox="0 0 24 24">
    <title>Auto light/dark, in dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round"
      class="icon-custom-derived-from-feather-sun-and-tabler-moon">
      <path d="M 8.282 7.007 C 8.385 7.007 8.494 7.007 8.595 7.007 C 5.18 10.184 6.481 15.869 10.942 17.24 C 12.275 17.648 13.706 17.589 15 17.066 C 12.851 22.236 5.91 23.143 2.505 18.696 C -0.897 14.249 1.791 7.786 7.342 7.063 C 7.652 7.021 7.965 7 8.282 7 L 8.282 7.007 Z"/>
      <line style="opacity: 50%" x1="18" y1="3.705" x2="18" y2="2.5"/>
      <line style="opacity: 50%" x1="18" y1="11.295" x2="18" y2="12.5"/>
      <line style="opacity: 50%" x1="15.316" y1="4.816" x2="14.464" y2="3.964"/>
      <line style="opacity: 50%" x1="20.711" y1="10.212" x2="21.563" y2="11.063"/>
      <line style="opacity: 50%" x1="14.205" y1="7.5" x2="13.001" y2="7.5"/>
      <line style="opacity: 50%" x1="21.795" y1="7.5" x2="23" y2="7.5"/>
      <line style="opacity: 50%" x1="15.316" y1="10.184" x2="14.464" y2="11.036"/>
      <line style="opacity: 50%" x1="20.711" y1="4.789" x2="21.563" y2="3.937"/>
      <circle style="opacity: 50%" cx="18" cy="7.5" r="2.169"/>
    </svg>
  </symbol>
  <symbol id="svg-pencil" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-pencil-code">
      <path d="M4 20h4l10.5 -10.5a2.828 2.828 0 1 0 -4 -4l-10.5 10.5v4" />
      <path d="M13.5 6.5l4 4" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" /
    </svg>
  </symbol>
  <symbol id="svg-eye" viewBox="0 0 24 24">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-eye-code">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M10 12a2 2 0 1 0 4 0a2 2 0 0 0 -4 0" />
      <path
        d="M11.11 17.958c-3.209 -.307 -5.91 -2.293 -8.11 -5.958c2.4 -4 5.4 -6 9 -6c3.6 0 6.6 2 9 6c-.21 .352 -.427 .688 -.647 1.008" />
      <path d="M20 21l2 -2l-2 -2" />
      <path d="M17 17l-2 2l2 2" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<a class="skip-to-content muted-link" href="#furo-main-content">Skip to content</a>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">transfer-learning-training 2.0.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
          <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../index.html">
  
  
  <span class="sidebar-brand-text">transfer-learning-training 2.0.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../pages/model_maker_training.html">Model_maker_training</a></li>
<li class="toctree-l1"><a class="reference internal" href="../pages/test_with_camera.html">test_with_camera</a></li>
<li class="toctree-l1"><a class="reference internal" href="People-detection.html">Using RoboFlow dataset to detect people using MediaPipe</a></li>
<li class="toctree-l1 current current-page"><a class="current reference internal" href="#">Using a custom made dataset to detect bolts using Mediapipe</a></li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="view-this-page">
  <a class="muted-link" href="../_sources/notebooks/Custom_training_bolt_detection.ipynb.txt" title="View this page">
    <svg><use href="#svg-eye"></use></svg>
    <span class="visually-hidden">View this page</span>
  </a>
</div>
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto-light"><use href="#svg-sun-with-moon"></use></svg>
              <svg class="theme-icon-when-auto-dark"><use href="#svg-moon-with-sun"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main" id="furo-main-content">
          <section id="Using-a-custom-made-dataset-to-detect-bolts-using-Mediapipe">
<h1>Using a custom made dataset to detect bolts using Mediapipe<a class="headerlink" href="#Using-a-custom-made-dataset-to-detect-bolts-using-Mediapipe" title="Link to this heading">¶</a></h1>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from google.colab import drive
drive.mount(&#39;/content/drive&#39;)
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Mounted at /content/drive
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>!pip install --upgrade pip
!pip install &#39;keras&lt;3.0.0&#39; mediapipe-model-maker
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)
Collecting pip
  Downloading pip-24.0-py3-none-any.whl (2.1 MB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">2.1/2.1 MB</span> <span class="ansi-red-fg">10.8 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Installing collected packages: pip
  Attempting uninstall: pip
    Found existing installation: pip 23.1.2
    Uninstalling pip-23.1.2:
      Successfully uninstalled pip-23.1.2
Successfully installed pip-24.0
Requirement already satisfied: keras&lt;3.0.0 in /usr/local/lib/python3.10/dist-packages (2.15.0)
Collecting mediapipe-model-maker
  Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl.metadata (1.6 kB)
Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.4.0)
Collecting mediapipe&gt;=0.10.0 (from mediapipe-model-maker)
  Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (1.25.2)
Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.8.0.76)
Requirement already satisfied: tensorflow&gt;=2.10 in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (2.15.0)
Collecting tensorflow-addons (from mediapipe-model-maker)
  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)
Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (4.9.4)
Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from mediapipe-model-maker) (0.16.1)
Collecting tf-models-official&gt;=2.13.1 (from mediapipe-model-maker)
  Downloading tf_models_official-2.16.0-py2.py3-none-any.whl.metadata (1.4 kB)
Requirement already satisfied: attrs&gt;=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (23.2.0)
Requirement already satisfied: flatbuffers&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (24.3.25)
Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (0.4.26)
Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (0.4.26+cuda12.cudnn89)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (3.7.1)
Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (2.2.1+cu121)
Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (4.8.0.76)
Requirement already satisfied: protobuf&lt;4,&gt;=3.11 in /usr/local/lib/python3.10/dist-packages (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (3.20.3)
Collecting sounddevice&gt;=0.4.4 (from mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading sounddevice-0.4.6-py3-none-any.whl.metadata (1.4 kB)
Requirement already satisfied: astunparse&gt;=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (1.6.3)
Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,&gt;=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (0.5.4)
Requirement already satisfied: google-pasta&gt;=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (0.2.0)
Requirement already satisfied: h5py&gt;=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (3.9.0)
Requirement already satisfied: libclang&gt;=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (18.1.1)
Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (0.2.0)
Requirement already satisfied: opt-einsum&gt;=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (3.3.0)
Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (24.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (67.7.2)
Requirement already satisfied: six&gt;=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (1.16.0)
Requirement already satisfied: termcolor&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (2.4.0)
Requirement already satisfied: typing-extensions&gt;=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (4.11.0)
Requirement already satisfied: wrapt&lt;1.15,&gt;=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (1.14.1)
Requirement already satisfied: tensorflow-io-gcs-filesystem&gt;=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (0.36.0)
Requirement already satisfied: grpcio&lt;2.0,&gt;=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (1.62.1)
Requirement already satisfied: tensorboard&lt;2.16,&gt;=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (2.15.2)
Requirement already satisfied: tensorflow-estimator&lt;2.16,&gt;=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (2.15.0)
Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (3.0.10)
Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (9.4.0)
Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (0.5.0)
Requirement already satisfied: google-api-python-client&gt;=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2.84.0)
Collecting immutabledict (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)
Requirement already satisfied: kaggle&gt;=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (1.5.16)
Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (4.1.3)
Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (4.9.0.80)
Requirement already satisfied: pandas&gt;=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2.0.3)
Requirement already satisfied: psutil&gt;=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (5.9.5)
Requirement already satisfied: py-cpuinfo&gt;=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (9.0.0)
Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2.0.7)
Requirement already satisfied: pyyaml&gt;=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (6.0.1)
Collecting sacrebleu (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">58.0/58.0 kB</span> <span class="ansi-red-fg">2.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Requirement already satisfied: scipy&gt;=0.19.1 in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (1.11.4)
Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (0.1.99)
Collecting seqeval (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading seqeval-1.2.2.tar.gz (43 kB)
     <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">43.6/43.6 kB</span> <span class="ansi-red-fg">3.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
  Preparing metadata (setup.py) ... done
Collecting tensorflow-model-optimization&gt;=0.4.1 (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)
Collecting tensorflow-text~=2.16.1 (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)
Collecting tensorflow&gt;=2.10 (from mediapipe-model-maker)
  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.3 kB)
Collecting tf-keras&gt;=2.16.0 (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)
Requirement already satisfied: tf-slim&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (1.1.0)
Collecting h5py&gt;=3.10.0 (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker)
  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)
Collecting ml-dtypes~=0.3.1 (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker)
  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)
Requirement already satisfied: requests&lt;3,&gt;=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (2.31.0)
Collecting tensorboard&lt;2.17,&gt;=2.16 (from tensorflow&gt;=2.10-&gt;mediapipe-model-maker)
  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)
INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.
Collecting tf-models-official&gt;=2.13.1 (from mediapipe-model-maker)
  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)
Collecting tensorflow-text~=2.15.0 (from tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)
Requirement already satisfied: tf-keras&gt;=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub-&gt;mediapipe-model-maker) (2.15.1)
Collecting typeguard&lt;3.0.0,&gt;=2.7 (from tensorflow-addons-&gt;mediapipe-model-maker)
  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)
Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-&gt;mediapipe-model-maker) (8.1.7)
Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-&gt;mediapipe-model-maker) (0.1.8)
Requirement already satisfied: etils&gt;=0.9.0 in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]&gt;=0.9.0-&gt;tensorflow-datasets-&gt;mediapipe-model-maker) (1.7.0)
Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-&gt;mediapipe-model-maker) (2.3)
Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-&gt;mediapipe-model-maker) (1.14.0)
Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-&gt;mediapipe-model-maker) (0.10.2)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-&gt;mediapipe-model-maker) (4.66.2)
Requirement already satisfied: array-record&gt;=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-&gt;mediapipe-model-maker) (0.5.1)
Requirement already satisfied: wheel&lt;1.0,&gt;=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse&gt;=1.6.0-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (0.43.0)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]&gt;=0.9.0-&gt;tensorflow-datasets-&gt;mediapipe-model-maker) (2023.6.0)
Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]&gt;=0.9.0-&gt;tensorflow-datasets-&gt;mediapipe-model-maker) (6.4.0)
Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]&gt;=0.9.0-&gt;tensorflow-datasets-&gt;mediapipe-model-maker) (3.18.1)
Requirement already satisfied: httplib2&lt;1dev,&gt;=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (0.22.0)
Requirement already satisfied: google-auth&lt;3.0.0dev,&gt;=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2.27.0)
Requirement already satisfied: google-auth-httplib2&gt;=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (0.1.1)
Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,&lt;3.0.0dev,&gt;=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2.11.1)
Requirement already satisfied: uritemplate&lt;5,&gt;=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client&gt;=1.6.7-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (4.1.1)
Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle&gt;=1.3.9-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2024.2.2)
Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle&gt;=1.3.9-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2.8.2)
Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle&gt;=1.3.9-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (8.0.4)
Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle&gt;=1.3.9-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2.0.7)
Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle&gt;=1.3.9-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (6.1.0)
Requirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=0.22.0-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2023.4)
Requirement already satisfied: tzdata&gt;=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas&gt;=0.22.0-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2024.1)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&lt;3,&gt;=2.21.0-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (3.7)
Requirement already satisfied: CFFI&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice&gt;=0.4.4-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (1.16.0)
Requirement already satisfied: google-auth-oauthlib&lt;2,&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.16,&gt;=2.15-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (1.2.0)
Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.16,&gt;=2.15-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (3.6)
Requirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.16,&gt;=2.15-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (0.7.2)
Requirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&lt;2.16,&gt;=2.15-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (3.0.2)
Requirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (1.2.1)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (0.12.1)
Requirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (4.51.0)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (1.4.5)
Requirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (3.1.2)
Requirement already satisfied: pyasn1&gt;=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (0.6.0)
Requirement already satisfied: pyasn1-modules&gt;=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (0.4.0)
Requirement already satisfied: rsa&gt;=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (4.9)
Collecting portalocker (from sacrebleu-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)
Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (2023.12.25)
Requirement already satisfied: tabulate&gt;=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (0.9.0)
Collecting colorama (from sacrebleu-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker)
  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)
Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (4.9.4)
Requirement already satisfied: scikit-learn&gt;=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (1.2.2)
Requirement already satisfied: googleapis-common-protos&lt;2,&gt;=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata-&gt;tensorflow-datasets-&gt;mediapipe-model-maker) (1.63.0)
Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (3.13.4)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (1.12)
Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (3.3)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (3.1.3)
Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cublas-cu12==12.1.3.1 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cufft-cu12==11.0.2.54 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-curand-cu12==10.3.2.106 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)
Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)
Collecting nvidia-nccl-cu12==2.19.3 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)
Collecting nvidia-nvtx-cu12==12.1.105 (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)
Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (2.2.0)
Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107-&gt;torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker)
  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)
Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI&gt;=1.0-&gt;sounddevice&gt;=0.4.4-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (2.22)
Requirement already satisfied: cachetools&lt;6.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth&lt;3.0.0dev,&gt;=1.19.0-&gt;google-api-python-client&gt;=1.6.7-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (5.3.3)
Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib&lt;2,&gt;=0.5-&gt;tensorboard&lt;2.16,&gt;=2.15-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (1.3.1)
Requirement already satisfied: joblib&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (1.4.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn&gt;=0.21.3-&gt;seqeval-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (3.4.0)
Requirement already satisfied: MarkupSafe&gt;=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard&lt;2.16,&gt;=2.15-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (2.1.5)
Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach-&gt;kaggle&gt;=1.3.9-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (0.5.1)
Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify-&gt;kaggle&gt;=1.3.9-&gt;tf-models-official&gt;=2.13.1-&gt;mediapipe-model-maker) (1.3)
Requirement already satisfied: mpmath&gt;=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch-&gt;mediapipe&gt;=0.10.0-&gt;mediapipe-model-maker) (1.3.0)
Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;2,&gt;=0.5-&gt;tensorboard&lt;2.16,&gt;=2.15-&gt;tensorflow&gt;=2.10-&gt;mediapipe-model-maker) (3.2.2)
Downloading mediapipe_model_maker-0.2.1.3-py3-none-any.whl (127 kB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">128.0/128.0 kB</span> <span class="ansi-red-fg">8.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading mediapipe-0.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.6 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">35.6/35.6 MB</span> <span class="ansi-red-fg">53.9 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">2.7/2.7 MB</span> <span class="ansi-red-fg">87.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">611.8/611.8 kB</span> <span class="ansi-red-fg">40.6 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)
Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">242.5/242.5 kB</span> <span class="ansi-red-fg">18.0 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">5.2/5.2 MB</span> <span class="ansi-red-fg">93.3 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)
Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)
Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">106.7/106.7 kB</span> <span class="ansi-red-fg">10.2 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">410.6/410.6 MB</span> <span class="ansi-red-fg">4.0 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">14.1/14.1 MB</span> <span class="ansi-red-fg">110.0 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">23.7/23.7 MB</span> <span class="ansi-red-fg">81.6 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">823.6/823.6 kB</span> <span class="ansi-red-fg">51.6 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">731.7/731.7 MB</span> <span class="ansi-red-fg">2.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">121.6/121.6 MB</span> <span class="ansi-red-fg">6.6 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">56.5/56.5 MB</span> <span class="ansi-red-fg">13.0 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">124.2/124.2 MB</span> <span class="ansi-red-fg">7.5 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">196.0/196.0 MB</span> <span class="ansi-red-fg">6.2 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">166.0/166.0 MB</span> <span class="ansi-red-fg">6.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">99.1/99.1 kB</span> <span class="ansi-red-fg">8.8 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)
Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)
Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)
   <span class="ansi-black-intense-fg">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span class="ansi-green-fg">21.1/21.1 MB</span> <span class="ansi-red-fg">89.4 MB/s</span> eta <span class="ansi-cyan-fg">0:00:00</span>
Building wheels for collected packages: seqeval
  Building wheel for seqeval (setup.py) ... done
  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=73fd445a18d8d89801cc1200a2de6feee17584a5cdb6068bc196af1549081216
  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa
Successfully built seqeval
Installing collected packages: typeguard, tensorflow-model-optimization, portalocker, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, immutabledict, colorama, tensorflow-addons, sounddevice, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, seqeval, nvidia-cusolver-cu12, mediapipe, tensorflow-text, tf-models-official, mediapipe-model-maker
Successfully installed colorama-0.4.6 immutabledict-4.2.0 mediapipe-0.10.11 mediapipe-model-maker-0.2.1.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 portalocker-2.8.2 sacrebleu-2.4.2 seqeval-1.2.2 sounddevice-0.4.6 tensorflow-addons-0.23.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.15.0 tf-models-official-2.15.0 typeguard-2.13.3
<span class="ansi-yellow-fg">WARNING: Running pip as the &#39;root&#39; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv</span><span class="ansi-yellow-fg">
</span>
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import os
import tensorflow as tf
assert tf.__version__.startswith(&#39;2&#39;)
from google.colab import files

from mediapipe_model_maker import object_detector
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning:

TensorFlow Addons (TFA) has ended development and introduction of new features.
TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.
Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP).

For more information see: https://github.com/tensorflow/addons/issues/2807

  warnings.warn(
</pre></div></div>
</div>
<section id="Creating-the-steps-for-training">
<h2>Creating the steps for training<a class="headerlink" href="#Creating-the-steps-for-training" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>class TransferLearning():
    &quot;&quot;&quot; Transfer Learning class for object detection using MediaPipe Model Maker
    2 datasets are required: train and validation

    Attributes:
        train_dataset_path: path to the train dataset
        validation_dataset_path: path to the validation dataset
        model: model to be trained
        train_data: train dataset
        validation_data: validation dataset
    &quot;&quot;&quot;
    def __init__(self):
        self.train_dataset_path = &quot;/content/drive/MyDrive/Detection-nuts-bolts.v1i.voc/train&quot;
        self.validation_dataset_path = &quot;/content/drive/MyDrive/Detection-nuts-bolts.v1i.voc/valid&quot;
        self.model = None
        self.train_data = None
        self.validation_data = None
        self.hparams = None
        self.options = None

    def load_data(self):
        &quot;&quot;&quot; Load train and validation datasets from the given paths        &quot;&quot;&quot;
        self.train_data = object_detector.DataLoader.from_pascal_voc(self.train_dataset_path)
        self.validation_data = object_detector.DataLoader.from_pascal_voc(self.validation_dataset_path)

    def train_model(self,batch_size=8, learning_rate=0.3, epochs=100, export_dir=&#39;exported_model&#39;):
        &quot;&quot;&quot; Train the model using the loaded datasets

        Args:
            batch_size: batch size for training
            learning_rate: learning rate for training
            epochs: number of epochs for training
            export_dir: directory to export the trained model
        &quot;&quot;&quot;
        self.hparams = object_detector.HParams(batch_size, learning_rate, epochs, export_dir)
        self.options = object_detector.ObjectDetectorOptions(
            supported_model=object_detector.SupportedModels.MOBILENET_V2,
            hparams=self.hparams
        )

        self.model = object_detector.ObjectDetector.create(
            train_data=self.train_data,
            validation_data=self.val_data,
            options=self.options)

    def evaluate_model(self,batch_size=8):
        &quot;&quot;&quot; Evaluate the trained model

        Args:
            batch_size: batch size for evaluation
        &quot;&quot;&quot;
        loss, metrics = self.model.evaluate(self.validation_data,batch_size)
        print(f&quot;Validation loss: {loss}&quot;)
        print(f&quot;Validation coco metrics: {metrics}&quot;)

    def export_model(self):
        &quot;&quot;&quot; Export the trained model &quot;&quot;&quot;
        self.model.export_model(&#39;bolt-detection.tflite&#39;)
        print(f&quot;Model exported&quot;)
<br/><br/><br/></pre></div>
</div>
</div>
</section>
<section id="Loading-the-data,-and-training">
<h2>Loading the data, and training<a class="headerlink" href="#Loading-the-data,-and-training" title="Link to this heading">¶</a></h2>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>TransferLearning_model = TransferLearning()
TransferLearning_model.load_data()
TransferLearning_model.train_model()
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Downloading https://storage.googleapis.com/tf_model_garden/vision/qat/mobilenetv2_ssd_coco/mobilenetv2_ssd_i256_ckpt.tar.gz to /tmp/model_maker/object_detector/mobilenetv2_i256
Model: &#34;retina_net_model&#34;
_________________________________________________________________
 Layer (type)                Output Shape              Param #
=================================================================
 mobile_net_1 (MobileNet)    {&#39;2&#39;: (None, 64, 64, 24   2257984
                             ),
                              &#39;3&#39;: (None, 32, 32, 32
                             ),
                              &#39;4&#39;: (None, 16, 16, 96
                             ),
                              &#39;5&#39;: (None, 8, 8, 320)
                             , &#39;6&#39;: (None, 8, 8, 128
                             0)}

 fpn_1 (FPN)                 {&#39;5&#39;: (None, 8, 8, 128)   149056
                             , &#39;4&#39;: (None, 16, 16, 1
                             28),
                              &#39;3&#39;: (None, 32, 32, 12
                             8),
                              &#39;6&#39;: (None, 4, 4, 128)
                             , &#39;7&#39;: (None, 2, 2, 128
                             )}

 multilevel_detection_gener  multiple                  0 (unused)
 ator (MultilevelDetectionG
 enerator)

 retina_net_head_1 (RetinaN  ({&#39;3&#39;: (None, 32, 32, 1   171062
 etHead)                     8),
                              &#39;4&#39;: (None, 16, 16, 18
                             ),
                              &#39;5&#39;: (None, 8, 8, 18),
                              &#39;6&#39;: (None, 4, 4, 18),
                              &#39;7&#39;: (None, 2, 2, 18)}
                             , {&#39;3&#39;: (None, 32, 32,
                             36),
                              &#39;4&#39;: (None, 16, 16, 36
                             ),
                              &#39;5&#39;: (None, 8, 8, 36),
                              &#39;6&#39;: (None, 4, 4, 36),
                              &#39;7&#39;: (None, 2, 2, 36)}
                             , {})

=================================================================
Total params: 2578102 (9.83 MB)
Trainable params: 2532470 (9.66 MB)
Non-trainable params: 45632 (178.25 KB)
_________________________________________________________________
Epoch 1/100
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  warnings.warn(
WARNING:tensorflow:Gradients do not exist for variables [&#39;conv2dbn_block_3/batch_normalization/gamma:0&#39;, &#39;conv2dbn_block_3/batch_normalization/beta:0&#39;] when minimizing the loss. If you&#39;re using `model.compile()`, did you forget to provide a `loss` argument?
WARNING:tensorflow:Gradients do not exist for variables [&#39;conv2dbn_block_3/batch_normalization/gamma:0&#39;, &#39;conv2dbn_block_3/batch_normalization/beta:0&#39;] when minimizing the loss. If you&#39;re using `model.compile()`, did you forget to provide a `loss` argument?
WARNING:tensorflow:Gradients do not exist for variables [&#39;conv2dbn_block_3/batch_normalization/gamma:0&#39;, &#39;conv2dbn_block_3/batch_normalization/beta:0&#39;] when minimizing the loss. If you&#39;re using `model.compile()`, did you forget to provide a `loss` argument?
WARNING:tensorflow:Gradients do not exist for variables [&#39;conv2dbn_block_3/batch_normalization/gamma:0&#39;, &#39;conv2dbn_block_3/batch_normalization/beta:0&#39;] when minimizing the loss. If you&#39;re using `model.compile()`, did you forget to provide a `loss` argument?
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
30/30 [==============================] - 66s 441ms/step - total_loss: 14.3356 - cls_loss: 13.9902 - box_loss: 0.0058 - model_loss: 14.2806 - val_total_loss: 1.0421 - val_cls_loss: 0.8848 - val_box_loss: 0.0020 - val_model_loss: 0.9872
Epoch 2/100
30/30 [==============================] - 5s 176ms/step - total_loss: 1.1946 - cls_loss: 0.9375 - box_loss: 0.0040 - model_loss: 1.1396 - val_total_loss: 0.8976 - val_cls_loss: 0.7552 - val_box_loss: 0.0017 - val_model_loss: 0.8426
Epoch 3/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.9612 - cls_loss: 0.7566 - box_loss: 0.0030 - model_loss: 0.9062 - val_total_loss: 0.6888 - val_cls_loss: 0.5560 - val_box_loss: 0.0016 - val_model_loss: 0.6338
Epoch 4/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.7521 - cls_loss: 0.5655 - box_loss: 0.0026 - model_loss: 0.6972 - val_total_loss: 0.5471 - val_cls_loss: 0.4144 - val_box_loss: 0.0016 - val_model_loss: 0.4921
Epoch 5/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.5779 - cls_loss: 0.4233 - box_loss: 0.0020 - model_loss: 0.5229 - val_total_loss: 0.4687 - val_cls_loss: 0.3420 - val_box_loss: 0.0014 - val_model_loss: 0.4137
Epoch 6/100
30/30 [==============================] - 6s 211ms/step - total_loss: 0.4730 - cls_loss: 0.3290 - box_loss: 0.0018 - model_loss: 0.4181 - val_total_loss: 0.4130 - val_cls_loss: 0.2878 - val_box_loss: 0.0014 - val_model_loss: 0.3580
Epoch 7/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.4050 - cls_loss: 0.2677 - box_loss: 0.0016 - model_loss: 0.3501 - val_total_loss: 0.3947 - val_cls_loss: 0.2682 - val_box_loss: 0.0014 - val_model_loss: 0.3398
Epoch 8/100
30/30 [==============================] - 6s 189ms/step - total_loss: 0.3531 - cls_loss: 0.2312 - box_loss: 0.0013 - model_loss: 0.2981 - val_total_loss: 0.3557 - val_cls_loss: 0.2361 - val_box_loss: 0.0013 - val_model_loss: 0.3007
Epoch 9/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.3165 - cls_loss: 0.1939 - box_loss: 0.0014 - model_loss: 0.2615 - val_total_loss: 0.3577 - val_cls_loss: 0.2351 - val_box_loss: 0.0014 - val_model_loss: 0.3028
Epoch 10/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.2874 - cls_loss: 0.1704 - box_loss: 0.0012 - model_loss: 0.2324 - val_total_loss: 0.3425 - val_cls_loss: 0.2216 - val_box_loss: 0.0013 - val_model_loss: 0.2875
Epoch 11/100
30/30 [==============================] - 7s 240ms/step - total_loss: 0.2890 - cls_loss: 0.1581 - box_loss: 0.0015 - model_loss: 0.2341 - val_total_loss: 0.3433 - val_cls_loss: 0.2185 - val_box_loss: 0.0014 - val_model_loss: 0.2883
Epoch 12/100
30/30 [==============================] - 6s 205ms/step - total_loss: 0.2900 - cls_loss: 0.1405 - box_loss: 0.0019 - model_loss: 0.2351 - val_total_loss: 0.3282 - val_cls_loss: 0.2080 - val_box_loss: 0.0013 - val_model_loss: 0.2732
Epoch 13/100
30/30 [==============================] - 6s 198ms/step - total_loss: 0.2404 - cls_loss: 0.1235 - box_loss: 0.0012 - model_loss: 0.1854 - val_total_loss: 0.3248 - val_cls_loss: 0.2061 - val_box_loss: 0.0013 - val_model_loss: 0.2699
Epoch 14/100
30/30 [==============================] - 6s 206ms/step - total_loss: 0.2353 - cls_loss: 0.1144 - box_loss: 0.0013 - model_loss: 0.1804 - val_total_loss: 0.3236 - val_cls_loss: 0.2079 - val_box_loss: 0.0012 - val_model_loss: 0.2686
Epoch 15/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.2212 - cls_loss: 0.1204 - box_loss: 9.1521e-04 - model_loss: 0.1662 - val_total_loss: 0.3054 - val_cls_loss: 0.1907 - val_box_loss: 0.0012 - val_model_loss: 0.2504
Epoch 16/100
30/30 [==============================] - 6s 213ms/step - total_loss: 0.2121 - cls_loss: 0.1135 - box_loss: 8.7249e-04 - model_loss: 0.1571 - val_total_loss: 0.3318 - val_cls_loss: 0.2135 - val_box_loss: 0.0013 - val_model_loss: 0.2769
Epoch 17/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.2067 - cls_loss: 0.1011 - box_loss: 0.0010 - model_loss: 0.1518 - val_total_loss: 0.3385 - val_cls_loss: 0.2174 - val_box_loss: 0.0013 - val_model_loss: 0.2835
Epoch 18/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.1969 - cls_loss: 0.0953 - box_loss: 9.3325e-04 - model_loss: 0.1419 - val_total_loss: 0.3334 - val_cls_loss: 0.2168 - val_box_loss: 0.0012 - val_model_loss: 0.2784
Epoch 19/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.1938 - cls_loss: 0.0807 - box_loss: 0.0012 - model_loss: 0.1389 - val_total_loss: 0.3305 - val_cls_loss: 0.2077 - val_box_loss: 0.0014 - val_model_loss: 0.2755
Epoch 20/100
30/30 [==============================] - 6s 199ms/step - total_loss: 0.2085 - cls_loss: 0.0807 - box_loss: 0.0015 - model_loss: 0.1535 - val_total_loss: 0.3459 - val_cls_loss: 0.2253 - val_box_loss: 0.0013 - val_model_loss: 0.2910
Epoch 21/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.1651 - cls_loss: 0.0721 - box_loss: 7.6187e-04 - model_loss: 0.1102 - val_total_loss: 0.3273 - val_cls_loss: 0.2085 - val_box_loss: 0.0013 - val_model_loss: 0.2723
Epoch 22/100
30/30 [==============================] - 6s 199ms/step - total_loss: 0.1857 - cls_loss: 0.0766 - box_loss: 0.0011 - model_loss: 0.1308 - val_total_loss: 0.3338 - val_cls_loss: 0.2168 - val_box_loss: 0.0012 - val_model_loss: 0.2788
Epoch 23/100
30/30 [==============================] - 6s 204ms/step - total_loss: 0.1784 - cls_loss: 0.0817 - box_loss: 8.3515e-04 - model_loss: 0.1235 - val_total_loss: 0.3349 - val_cls_loss: 0.2178 - val_box_loss: 0.0012 - val_model_loss: 0.2800
Epoch 24/100
30/30 [==============================] - 5s 169ms/step - total_loss: 0.2730 - cls_loss: 0.1471 - box_loss: 0.0014 - model_loss: 0.2180 - val_total_loss: 0.4500 - val_cls_loss: 0.3031 - val_box_loss: 0.0018 - val_model_loss: 0.3949
Epoch 25/100
30/30 [==============================] - 6s 189ms/step - total_loss: 0.2669 - cls_loss: 0.1418 - box_loss: 0.0014 - model_loss: 0.2118 - val_total_loss: 0.3923 - val_cls_loss: 0.2517 - val_box_loss: 0.0017 - val_model_loss: 0.3372
Epoch 26/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1942 - cls_loss: 0.0968 - box_loss: 8.4464e-04 - model_loss: 0.1390 - val_total_loss: 0.3679 - val_cls_loss: 0.2363 - val_box_loss: 0.0015 - val_model_loss: 0.3128
Epoch 27/100
30/30 [==============================] - 6s 211ms/step - total_loss: 0.1984 - cls_loss: 0.0896 - box_loss: 0.0011 - model_loss: 0.1433 - val_total_loss: 0.3603 - val_cls_loss: 0.2296 - val_box_loss: 0.0015 - val_model_loss: 0.3051
Epoch 28/100
30/30 [==============================] - 6s 200ms/step - total_loss: 0.1724 - cls_loss: 0.0719 - box_loss: 9.0732e-04 - model_loss: 0.1173 - val_total_loss: 0.3525 - val_cls_loss: 0.2263 - val_box_loss: 0.0014 - val_model_loss: 0.2973
Epoch 29/100
30/30 [==============================] - 5s 176ms/step - total_loss: 0.1706 - cls_loss: 0.0753 - box_loss: 8.0214e-04 - model_loss: 0.1155 - val_total_loss: 0.3587 - val_cls_loss: 0.2341 - val_box_loss: 0.0014 - val_model_loss: 0.3036
Epoch 30/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.1683 - cls_loss: 0.0783 - box_loss: 6.9788e-04 - model_loss: 0.1132 - val_total_loss: 0.3515 - val_cls_loss: 0.2311 - val_box_loss: 0.0013 - val_model_loss: 0.2964
Epoch 31/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.1615 - cls_loss: 0.0685 - box_loss: 7.5762e-04 - model_loss: 0.1064 - val_total_loss: 0.3618 - val_cls_loss: 0.2374 - val_box_loss: 0.0014 - val_model_loss: 0.3067
Epoch 32/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.1568 - cls_loss: 0.0537 - box_loss: 9.6010e-04 - model_loss: 0.1017 - val_total_loss: 0.3441 - val_cls_loss: 0.2237 - val_box_loss: 0.0013 - val_model_loss: 0.2889
Epoch 33/100
30/30 [==============================] - 6s 190ms/step - total_loss: 0.1450 - cls_loss: 0.0562 - box_loss: 6.7395e-04 - model_loss: 0.0899 - val_total_loss: 0.3508 - val_cls_loss: 0.2304 - val_box_loss: 0.0013 - val_model_loss: 0.2957
Epoch 34/100
30/30 [==============================] - 6s 203ms/step - total_loss: 0.1400 - cls_loss: 0.0587 - box_loss: 5.2355e-04 - model_loss: 0.0849 - val_total_loss: 0.3581 - val_cls_loss: 0.2337 - val_box_loss: 0.0014 - val_model_loss: 0.3030
Epoch 35/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1359 - cls_loss: 0.0509 - box_loss: 5.9696e-04 - model_loss: 0.0808 - val_total_loss: 0.3723 - val_cls_loss: 0.2470 - val_box_loss: 0.0014 - val_model_loss: 0.3172
Epoch 36/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1478 - cls_loss: 0.0436 - box_loss: 9.8155e-04 - model_loss: 0.0927 - val_total_loss: 0.3633 - val_cls_loss: 0.2393 - val_box_loss: 0.0014 - val_model_loss: 0.3082
Epoch 37/100
30/30 [==============================] - 6s 196ms/step - total_loss: 0.1221 - cls_loss: 0.0376 - box_loss: 5.8971e-04 - model_loss: 0.0670 - val_total_loss: 0.3657 - val_cls_loss: 0.2446 - val_box_loss: 0.0013 - val_model_loss: 0.3106
Epoch 38/100
30/30 [==============================] - 6s 210ms/step - total_loss: 0.1150 - cls_loss: 0.0345 - box_loss: 5.0973e-04 - model_loss: 0.0599 - val_total_loss: 0.3698 - val_cls_loss: 0.2469 - val_box_loss: 0.0014 - val_model_loss: 0.3147
Epoch 39/100
30/30 [==============================] - 6s 184ms/step - total_loss: 0.1236 - cls_loss: 0.0358 - box_loss: 6.5545e-04 - model_loss: 0.0685 - val_total_loss: 0.3709 - val_cls_loss: 0.2474 - val_box_loss: 0.0014 - val_model_loss: 0.3158
Epoch 40/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.1369 - cls_loss: 0.0365 - box_loss: 9.0680e-04 - model_loss: 0.0818 - val_total_loss: 0.3698 - val_cls_loss: 0.2475 - val_box_loss: 0.0013 - val_model_loss: 0.3147
Epoch 41/100
30/30 [==============================] - 6s 200ms/step - total_loss: 0.1268 - cls_loss: 0.0422 - box_loss: 5.9183e-04 - model_loss: 0.0717 - val_total_loss: 0.3802 - val_cls_loss: 0.2596 - val_box_loss: 0.0013 - val_model_loss: 0.3252
Epoch 42/100
30/30 [==============================] - 5s 169ms/step - total_loss: 0.1141 - cls_loss: 0.0362 - box_loss: 4.5653e-04 - model_loss: 0.0591 - val_total_loss: 0.3801 - val_cls_loss: 0.2600 - val_box_loss: 0.0013 - val_model_loss: 0.3251
Epoch 43/100
30/30 [==============================] - 6s 213ms/step - total_loss: 0.1229 - cls_loss: 0.0412 - box_loss: 5.3317e-04 - model_loss: 0.0679 - val_total_loss: 0.3831 - val_cls_loss: 0.2646 - val_box_loss: 0.0013 - val_model_loss: 0.3281
Epoch 44/100
30/30 [==============================] - 6s 183ms/step - total_loss: 0.1282 - cls_loss: 0.0377 - box_loss: 7.0942e-04 - model_loss: 0.0731 - val_total_loss: 0.4143 - val_cls_loss: 0.2939 - val_box_loss: 0.0013 - val_model_loss: 0.3593
Epoch 45/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.1121 - cls_loss: 0.0323 - box_loss: 4.9546e-04 - model_loss: 0.0570 - val_total_loss: 0.4145 - val_cls_loss: 0.2963 - val_box_loss: 0.0013 - val_model_loss: 0.3595
Epoch 46/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1132 - cls_loss: 0.0367 - box_loss: 4.2932e-04 - model_loss: 0.0582 - val_total_loss: 0.4164 - val_cls_loss: 0.2979 - val_box_loss: 0.0013 - val_model_loss: 0.3614
Epoch 47/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.1073 - cls_loss: 0.0276 - box_loss: 4.9285e-04 - model_loss: 0.0522 - val_total_loss: 0.4117 - val_cls_loss: 0.2921 - val_box_loss: 0.0013 - val_model_loss: 0.3567
Epoch 48/100
30/30 [==============================] - 6s 200ms/step - total_loss: 0.1153 - cls_loss: 0.0361 - box_loss: 4.8306e-04 - model_loss: 0.0603 - val_total_loss: 0.4164 - val_cls_loss: 0.2973 - val_box_loss: 0.0013 - val_model_loss: 0.3614
Epoch 49/100
30/30 [==============================] - 5s 177ms/step - total_loss: 0.1034 - cls_loss: 0.0251 - box_loss: 4.6587e-04 - model_loss: 0.0484 - val_total_loss: 0.4252 - val_cls_loss: 0.3047 - val_box_loss: 0.0013 - val_model_loss: 0.3702
Epoch 50/100
30/30 [==============================] - 6s 208ms/step - total_loss: 0.1059 - cls_loss: 0.0282 - box_loss: 4.5344e-04 - model_loss: 0.0508 - val_total_loss: 0.4087 - val_cls_loss: 0.2913 - val_box_loss: 0.0012 - val_model_loss: 0.3537
Epoch 51/100
30/30 [==============================] - 5s 169ms/step - total_loss: 0.1270 - cls_loss: 0.0375 - box_loss: 6.9003e-04 - model_loss: 0.0720 - val_total_loss: 0.3905 - val_cls_loss: 0.2727 - val_box_loss: 0.0013 - val_model_loss: 0.3355
Epoch 52/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.1051 - cls_loss: 0.0278 - box_loss: 4.4440e-04 - model_loss: 0.0501 - val_total_loss: 0.4038 - val_cls_loss: 0.2828 - val_box_loss: 0.0013 - val_model_loss: 0.3488
Epoch 53/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1089 - cls_loss: 0.0251 - box_loss: 5.7645e-04 - model_loss: 0.0539 - val_total_loss: 0.4134 - val_cls_loss: 0.2921 - val_box_loss: 0.0013 - val_model_loss: 0.3584
Epoch 54/100
30/30 [==============================] - 6s 211ms/step - total_loss: 0.1325 - cls_loss: 0.0270 - box_loss: 0.0010 - model_loss: 0.0775 - val_total_loss: 0.4376 - val_cls_loss: 0.3080 - val_box_loss: 0.0015 - val_model_loss: 0.3826
Epoch 55/100
30/30 [==============================] - 6s 198ms/step - total_loss: 0.1220 - cls_loss: 0.0314 - box_loss: 7.1229e-04 - model_loss: 0.0670 - val_total_loss: 0.4177 - val_cls_loss: 0.2935 - val_box_loss: 0.0014 - val_model_loss: 0.3627
Epoch 56/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.1226 - cls_loss: 0.0370 - box_loss: 6.1162e-04 - model_loss: 0.0676 - val_total_loss: 0.4244 - val_cls_loss: 0.3003 - val_box_loss: 0.0014 - val_model_loss: 0.3694
Epoch 57/100
30/30 [==============================] - 6s 201ms/step - total_loss: 0.1268 - cls_loss: 0.0327 - box_loss: 7.8454e-04 - model_loss: 0.0719 - val_total_loss: 0.4210 - val_cls_loss: 0.2944 - val_box_loss: 0.0014 - val_model_loss: 0.3661
Epoch 58/100
30/30 [==============================] - 6s 193ms/step - total_loss: 0.1200 - cls_loss: 0.0247 - box_loss: 8.0744e-04 - model_loss: 0.0651 - val_total_loss: 0.4291 - val_cls_loss: 0.2992 - val_box_loss: 0.0015 - val_model_loss: 0.3741
Epoch 59/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.1347 - cls_loss: 0.0315 - box_loss: 9.6482e-04 - model_loss: 0.0797 - val_total_loss: 0.4318 - val_cls_loss: 0.3055 - val_box_loss: 0.0014 - val_model_loss: 0.3769
Epoch 60/100
30/30 [==============================] - 6s 204ms/step - total_loss: 0.1175 - cls_loss: 0.0228 - box_loss: 7.9551e-04 - model_loss: 0.0625 - val_total_loss: 0.4222 - val_cls_loss: 0.3009 - val_box_loss: 0.0013 - val_model_loss: 0.3673
Epoch 61/100
30/30 [==============================] - 5s 171ms/step - total_loss: 0.1253 - cls_loss: 0.0336 - box_loss: 7.3396e-04 - model_loss: 0.0703 - val_total_loss: 0.4221 - val_cls_loss: 0.3044 - val_box_loss: 0.0013 - val_model_loss: 0.3672
Epoch 62/100
30/30 [==============================] - 5s 171ms/step - total_loss: 0.1357 - cls_loss: 0.0332 - box_loss: 9.5000e-04 - model_loss: 0.0807 - val_total_loss: 0.4078 - val_cls_loss: 0.2856 - val_box_loss: 0.0013 - val_model_loss: 0.3529
Epoch 63/100
30/30 [==============================] - 6s 188ms/step - total_loss: 0.1301 - cls_loss: 0.0278 - box_loss: 9.4730e-04 - model_loss: 0.0752 - val_total_loss: 0.4084 - val_cls_loss: 0.2850 - val_box_loss: 0.0014 - val_model_loss: 0.3535
Epoch 64/100
30/30 [==============================] - 6s 194ms/step - total_loss: 0.1176 - cls_loss: 0.0258 - box_loss: 7.3795e-04 - model_loss: 0.0627 - val_total_loss: 0.4209 - val_cls_loss: 0.2949 - val_box_loss: 0.0014 - val_model_loss: 0.3660
Epoch 65/100
30/30 [==============================] - 7s 214ms/step - total_loss: 0.0941 - cls_loss: 0.0183 - box_loss: 4.1812e-04 - model_loss: 0.0392 - val_total_loss: 0.4439 - val_cls_loss: 0.3164 - val_box_loss: 0.0015 - val_model_loss: 0.3890
Epoch 66/100
30/30 [==============================] - 7s 214ms/step - total_loss: 0.1001 - cls_loss: 0.0215 - box_loss: 4.7330e-04 - model_loss: 0.0452 - val_total_loss: 0.4528 - val_cls_loss: 0.3231 - val_box_loss: 0.0015 - val_model_loss: 0.3979
Epoch 67/100
30/30 [==============================] - 6s 205ms/step - total_loss: 0.0969 - cls_loss: 0.0201 - box_loss: 4.3725e-04 - model_loss: 0.0419 - val_total_loss: 0.4511 - val_cls_loss: 0.3262 - val_box_loss: 0.0014 - val_model_loss: 0.3962
Epoch 68/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1109 - cls_loss: 0.0300 - box_loss: 5.1976e-04 - model_loss: 0.0560 - val_total_loss: 0.4423 - val_cls_loss: 0.3137 - val_box_loss: 0.0015 - val_model_loss: 0.3874
Epoch 69/100
30/30 [==============================] - 5s 178ms/step - total_loss: 0.1259 - cls_loss: 0.0408 - box_loss: 6.0400e-04 - model_loss: 0.0710 - val_total_loss: 0.4344 - val_cls_loss: 0.3124 - val_box_loss: 0.0013 - val_model_loss: 0.3795
Epoch 70/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.0959 - cls_loss: 0.0193 - box_loss: 4.3317e-04 - model_loss: 0.0410 - val_total_loss: 0.4373 - val_cls_loss: 0.3190 - val_box_loss: 0.0013 - val_model_loss: 0.3824
Epoch 71/100
30/30 [==============================] - 6s 194ms/step - total_loss: 0.0959 - cls_loss: 0.0186 - box_loss: 4.4751e-04 - model_loss: 0.0410 - val_total_loss: 0.4540 - val_cls_loss: 0.3352 - val_box_loss: 0.0013 - val_model_loss: 0.3991
Epoch 72/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.1016 - cls_loss: 0.0191 - box_loss: 5.5197e-04 - model_loss: 0.0467 - val_total_loss: 0.4385 - val_cls_loss: 0.3216 - val_box_loss: 0.0012 - val_model_loss: 0.3836
Epoch 73/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1186 - cls_loss: 0.0295 - box_loss: 6.8361e-04 - model_loss: 0.0637 - val_total_loss: 0.4404 - val_cls_loss: 0.3198 - val_box_loss: 0.0013 - val_model_loss: 0.3855
Epoch 74/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1171 - cls_loss: 0.0261 - box_loss: 7.2368e-04 - model_loss: 0.0623 - val_total_loss: 0.4599 - val_cls_loss: 0.3378 - val_box_loss: 0.0013 - val_model_loss: 0.4050
Epoch 75/100
30/30 [==============================] - 6s 191ms/step - total_loss: 0.1011 - cls_loss: 0.0151 - box_loss: 6.2282e-04 - model_loss: 0.0463 - val_total_loss: 0.4596 - val_cls_loss: 0.3351 - val_box_loss: 0.0014 - val_model_loss: 0.4048
Epoch 76/100
30/30 [==============================] - 6s 185ms/step - total_loss: 0.0905 - cls_loss: 0.0164 - box_loss: 3.8389e-04 - model_loss: 0.0356 - val_total_loss: 0.4861 - val_cls_loss: 0.3605 - val_box_loss: 0.0014 - val_model_loss: 0.4313
Epoch 77/100
30/30 [==============================] - 6s 209ms/step - total_loss: 0.1114 - cls_loss: 0.0264 - box_loss: 6.0414e-04 - model_loss: 0.0566 - val_total_loss: 0.4776 - val_cls_loss: 0.3508 - val_box_loss: 0.0014 - val_model_loss: 0.4228
Epoch 78/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.0958 - cls_loss: 0.0138 - box_loss: 5.4198e-04 - model_loss: 0.0409 - val_total_loss: 0.4794 - val_cls_loss: 0.3509 - val_box_loss: 0.0015 - val_model_loss: 0.4246
Epoch 79/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1001 - cls_loss: 0.0177 - box_loss: 5.5167e-04 - model_loss: 0.0452 - val_total_loss: 0.4825 - val_cls_loss: 0.3575 - val_box_loss: 0.0014 - val_model_loss: 0.4277
Epoch 80/100
30/30 [==============================] - 6s 186ms/step - total_loss: 0.1118 - cls_loss: 0.0280 - box_loss: 5.8003e-04 - model_loss: 0.0570 - val_total_loss: 0.4675 - val_cls_loss: 0.3453 - val_box_loss: 0.0013 - val_model_loss: 0.4127
Epoch 81/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.0891 - cls_loss: 0.0109 - box_loss: 4.6892e-04 - model_loss: 0.0343 - val_total_loss: 0.4521 - val_cls_loss: 0.3339 - val_box_loss: 0.0013 - val_model_loss: 0.3972
Epoch 82/100
30/30 [==============================] - 5s 177ms/step - total_loss: 0.1048 - cls_loss: 0.0209 - box_loss: 5.8195e-04 - model_loss: 0.0500 - val_total_loss: 0.4535 - val_cls_loss: 0.3352 - val_box_loss: 0.0013 - val_model_loss: 0.3987
Epoch 83/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.1186 - cls_loss: 0.0267 - box_loss: 7.4208e-04 - model_loss: 0.0638 - val_total_loss: 0.4401 - val_cls_loss: 0.3200 - val_box_loss: 0.0013 - val_model_loss: 0.3853
Epoch 84/100
30/30 [==============================] - 6s 184ms/step - total_loss: 0.1037 - cls_loss: 0.0148 - box_loss: 6.8151e-04 - model_loss: 0.0489 - val_total_loss: 0.4640 - val_cls_loss: 0.3401 - val_box_loss: 0.0014 - val_model_loss: 0.4092
Epoch 85/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1100 - cls_loss: 0.0239 - box_loss: 6.2668e-04 - model_loss: 0.0552 - val_total_loss: 0.4728 - val_cls_loss: 0.3497 - val_box_loss: 0.0014 - val_model_loss: 0.4180
Epoch 86/100
30/30 [==============================] - 6s 203ms/step - total_loss: 0.0926 - cls_loss: 0.0169 - box_loss: 4.1826e-04 - model_loss: 0.0378 - val_total_loss: 0.4905 - val_cls_loss: 0.3678 - val_box_loss: 0.0014 - val_model_loss: 0.4357
Epoch 87/100
30/30 [==============================] - 6s 202ms/step - total_loss: 0.0854 - cls_loss: 0.0147 - box_loss: 3.1862e-04 - model_loss: 0.0306 - val_total_loss: 0.4375 - val_cls_loss: 0.3151 - val_box_loss: 0.0014 - val_model_loss: 0.3827
Epoch 88/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.0903 - cls_loss: 0.0165 - box_loss: 3.8001e-04 - model_loss: 0.0355 - val_total_loss: 0.4681 - val_cls_loss: 0.3383 - val_box_loss: 0.0015 - val_model_loss: 0.4133
Epoch 89/100
30/30 [==============================] - 6s 204ms/step - total_loss: 0.0956 - cls_loss: 0.0209 - box_loss: 3.9925e-04 - model_loss: 0.0408 - val_total_loss: 0.4716 - val_cls_loss: 0.3471 - val_box_loss: 0.0014 - val_model_loss: 0.4169
Epoch 90/100
30/30 [==============================] - 6s 206ms/step - total_loss: 0.0940 - cls_loss: 0.0182 - box_loss: 4.2096e-04 - model_loss: 0.0393 - val_total_loss: 0.4583 - val_cls_loss: 0.3342 - val_box_loss: 0.0014 - val_model_loss: 0.4035
Epoch 91/100
30/30 [==============================] - 6s 210ms/step - total_loss: 0.0909 - cls_loss: 0.0123 - box_loss: 4.7623e-04 - model_loss: 0.0361 - val_total_loss: 0.4585 - val_cls_loss: 0.3349 - val_box_loss: 0.0014 - val_model_loss: 0.4037
Epoch 92/100
30/30 [==============================] - 6s 181ms/step - total_loss: 0.0949 - cls_loss: 0.0115 - box_loss: 5.7280e-04 - model_loss: 0.0402 - val_total_loss: 0.4616 - val_cls_loss: 0.3369 - val_box_loss: 0.0014 - val_model_loss: 0.4069
Epoch 93/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.1141 - cls_loss: 0.0263 - box_loss: 6.6052e-04 - model_loss: 0.0593 - val_total_loss: 0.4672 - val_cls_loss: 0.3369 - val_box_loss: 0.0015 - val_model_loss: 0.4124
Epoch 94/100
30/30 [==============================] - 6s 210ms/step - total_loss: 0.1126 - cls_loss: 0.0160 - box_loss: 8.3728e-04 - model_loss: 0.0579 - val_total_loss: 0.4634 - val_cls_loss: 0.3342 - val_box_loss: 0.0015 - val_model_loss: 0.4087
Epoch 95/100
30/30 [==============================] - 6s 209ms/step - total_loss: 0.0937 - cls_loss: 0.0155 - box_loss: 4.7037e-04 - model_loss: 0.0390 - val_total_loss: 0.4526 - val_cls_loss: 0.3252 - val_box_loss: 0.0015 - val_model_loss: 0.3979
Epoch 96/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.0838 - cls_loss: 0.0101 - box_loss: 3.7900e-04 - model_loss: 0.0290 - val_total_loss: 0.4674 - val_cls_loss: 0.3381 - val_box_loss: 0.0015 - val_model_loss: 0.4127
Epoch 97/100
30/30 [==============================] - 6s 202ms/step - total_loss: 0.1081 - cls_loss: 0.0171 - box_loss: 7.2588e-04 - model_loss: 0.0534 - val_total_loss: 0.4780 - val_cls_loss: 0.3481 - val_box_loss: 0.0015 - val_model_loss: 0.4233
Epoch 98/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.0818 - cls_loss: 0.0094 - box_loss: 3.5368e-04 - model_loss: 0.0271 - val_total_loss: 0.4714 - val_cls_loss: 0.3459 - val_box_loss: 0.0014 - val_model_loss: 0.4167
Epoch 99/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.0778 - cls_loss: 0.0082 - box_loss: 2.9762e-04 - model_loss: 0.0231 - val_total_loss: 0.4700 - val_cls_loss: 0.3445 - val_box_loss: 0.0014 - val_model_loss: 0.4153
Epoch 100/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.0788 - cls_loss: 0.0074 - box_loss: 3.3287e-04 - model_loss: 0.0241 - val_total_loss: 0.4701 - val_cls_loss: 0.3474 - val_box_loss: 0.0014 - val_model_loss: 0.4154
</pre></div></div>
</div>
</section>
<section id="Evaluating-the-model">
<h2>Evaluating the model<a class="headerlink" href="#Evaluating-the-model" title="Link to this heading">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>TransferLearning_model.evaluate_model()
TransferLearning_model.export_model()
<br/></pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import re
import matplotlib.pyplot as plt
txt_file = &quot;&quot;&quot;0/30 [==============================] - 66s 441ms/step - total_loss: 14.3356 - cls_loss: 13.9902 - box_loss: 0.0058 - model_loss: 14.2806 - val_total_loss: 1.0421 - val_cls_loss: 0.8848 - val_box_loss: 0.0020 - val_model_loss: 0.9872
Epoch 2/100
30/30 [==============================] - 5s 176ms/step - total_loss: 1.1946 - cls_loss: 0.9375 - box_loss: 0.0040 - model_loss: 1.1396 - val_total_loss: 0.8976 - val_cls_loss: 0.7552 - val_box_loss: 0.0017 - val_model_loss: 0.8426
Epoch 3/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.9612 - cls_loss: 0.7566 - box_loss: 0.0030 - model_loss: 0.9062 - val_total_loss: 0.6888 - val_cls_loss: 0.5560 - val_box_loss: 0.0016 - val_model_loss: 0.6338
Epoch 4/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.7521 - cls_loss: 0.5655 - box_loss: 0.0026 - model_loss: 0.6972 - val_total_loss: 0.5471 - val_cls_loss: 0.4144 - val_box_loss: 0.0016 - val_model_loss: 0.4921
Epoch 5/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.5779 - cls_loss: 0.4233 - box_loss: 0.0020 - model_loss: 0.5229 - val_total_loss: 0.4687 - val_cls_loss: 0.3420 - val_box_loss: 0.0014 - val_model_loss: 0.4137
Epoch 6/100
30/30 [==============================] - 6s 211ms/step - total_loss: 0.4730 - cls_loss: 0.3290 - box_loss: 0.0018 - model_loss: 0.4181 - val_total_loss: 0.4130 - val_cls_loss: 0.2878 - val_box_loss: 0.0014 - val_model_loss: 0.3580
Epoch 7/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.4050 - cls_loss: 0.2677 - box_loss: 0.0016 - model_loss: 0.3501 - val_total_loss: 0.3947 - val_cls_loss: 0.2682 - val_box_loss: 0.0014 - val_model_loss: 0.3398
Epoch 8/100
30/30 [==============================] - 6s 189ms/step - total_loss: 0.3531 - cls_loss: 0.2312 - box_loss: 0.0013 - model_loss: 0.2981 - val_total_loss: 0.3557 - val_cls_loss: 0.2361 - val_box_loss: 0.0013 - val_model_loss: 0.3007
Epoch 9/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.3165 - cls_loss: 0.1939 - box_loss: 0.0014 - model_loss: 0.2615 - val_total_loss: 0.3577 - val_cls_loss: 0.2351 - val_box_loss: 0.0014 - val_model_loss: 0.3028
Epoch 10/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.2874 - cls_loss: 0.1704 - box_loss: 0.0012 - model_loss: 0.2324 - val_total_loss: 0.3425 - val_cls_loss: 0.2216 - val_box_loss: 0.0013 - val_model_loss: 0.2875
Epoch 11/100
30/30 [==============================] - 7s 240ms/step - total_loss: 0.2890 - cls_loss: 0.1581 - box_loss: 0.0015 - model_loss: 0.2341 - val_total_loss: 0.3433 - val_cls_loss: 0.2185 - val_box_loss: 0.0014 - val_model_loss: 0.2883
Epoch 12/100
30/30 [==============================] - 6s 205ms/step - total_loss: 0.2900 - cls_loss: 0.1405 - box_loss: 0.0019 - model_loss: 0.2351 - val_total_loss: 0.3282 - val_cls_loss: 0.2080 - val_box_loss: 0.0013 - val_model_loss: 0.2732
Epoch 13/100
30/30 [==============================] - 6s 198ms/step - total_loss: 0.2404 - cls_loss: 0.1235 - box_loss: 0.0012 - model_loss: 0.1854 - val_total_loss: 0.3248 - val_cls_loss: 0.2061 - val_box_loss: 0.0013 - val_model_loss: 0.2699
Epoch 14/100
30/30 [==============================] - 6s 206ms/step - total_loss: 0.2353 - cls_loss: 0.1144 - box_loss: 0.0013 - model_loss: 0.1804 - val_total_loss: 0.3236 - val_cls_loss: 0.2079 - val_box_loss: 0.0012 - val_model_loss: 0.2686
Epoch 15/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.2212 - cls_loss: 0.1204 - box_loss: 9.1521e-04 - model_loss: 0.1662 - val_total_loss: 0.3054 - val_cls_loss: 0.1907 - val_box_loss: 0.0012 - val_model_loss: 0.2504
Epoch 16/100
30/30 [==============================] - 6s 213ms/step - total_loss: 0.2121 - cls_loss: 0.1135 - box_loss: 8.7249e-04 - model_loss: 0.1571 - val_total_loss: 0.3318 - val_cls_loss: 0.2135 - val_box_loss: 0.0013 - val_model_loss: 0.2769
Epoch 17/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.2067 - cls_loss: 0.1011 - box_loss: 0.0010 - model_loss: 0.1518 - val_total_loss: 0.3385 - val_cls_loss: 0.2174 - val_box_loss: 0.0013 - val_model_loss: 0.2835
Epoch 18/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.1969 - cls_loss: 0.0953 - box_loss: 9.3325e-04 - model_loss: 0.1419 - val_total_loss: 0.3334 - val_cls_loss: 0.2168 - val_box_loss: 0.0012 - val_model_loss: 0.2784
Epoch 19/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.1938 - cls_loss: 0.0807 - box_loss: 0.0012 - model_loss: 0.1389 - val_total_loss: 0.3305 - val_cls_loss: 0.2077 - val_box_loss: 0.0014 - val_model_loss: 0.2755
Epoch 20/100
30/30 [==============================] - 6s 199ms/step - total_loss: 0.2085 - cls_loss: 0.0807 - box_loss: 0.0015 - model_loss: 0.1535 - val_total_loss: 0.3459 - val_cls_loss: 0.2253 - val_box_loss: 0.0013 - val_model_loss: 0.2910
Epoch 21/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.1651 - cls_loss: 0.0721 - box_loss: 7.6187e-04 - model_loss: 0.1102 - val_total_loss: 0.3273 - val_cls_loss: 0.2085 - val_box_loss: 0.0013 - val_model_loss: 0.2723
Epoch 22/100
30/30 [==============================] - 6s 199ms/step - total_loss: 0.1857 - cls_loss: 0.0766 - box_loss: 0.0011 - model_loss: 0.1308 - val_total_loss: 0.3338 - val_cls_loss: 0.2168 - val_box_loss: 0.0012 - val_model_loss: 0.2788
Epoch 23/100
30/30 [==============================] - 6s 204ms/step - total_loss: 0.1784 - cls_loss: 0.0817 - box_loss: 8.3515e-04 - model_loss: 0.1235 - val_total_loss: 0.3349 - val_cls_loss: 0.2178 - val_box_loss: 0.0012 - val_model_loss: 0.2800
Epoch 24/100
30/30 [==============================] - 5s 169ms/step - total_loss: 0.2730 - cls_loss: 0.1471 - box_loss: 0.0014 - model_loss: 0.2180 - val_total_loss: 0.4500 - val_cls_loss: 0.3031 - val_box_loss: 0.0018 - val_model_loss: 0.3949
Epoch 25/100
30/30 [==============================] - 6s 189ms/step - total_loss: 0.2669 - cls_loss: 0.1418 - box_loss: 0.0014 - model_loss: 0.2118 - val_total_loss: 0.3923 - val_cls_loss: 0.2517 - val_box_loss: 0.0017 - val_model_loss: 0.3372
Epoch 26/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1942 - cls_loss: 0.0968 - box_loss: 8.4464e-04 - model_loss: 0.1390 - val_total_loss: 0.3679 - val_cls_loss: 0.2363 - val_box_loss: 0.0015 - val_model_loss: 0.3128
Epoch 27/100
30/30 [==============================] - 6s 211ms/step - total_loss: 0.1984 - cls_loss: 0.0896 - box_loss: 0.0011 - model_loss: 0.1433 - val_total_loss: 0.3603 - val_cls_loss: 0.2296 - val_box_loss: 0.0015 - val_model_loss: 0.3051
Epoch 28/100
30/30 [==============================] - 6s 200ms/step - total_loss: 0.1724 - cls_loss: 0.0719 - box_loss: 9.0732e-04 - model_loss: 0.1173 - val_total_loss: 0.3525 - val_cls_loss: 0.2263 - val_box_loss: 0.0014 - val_model_loss: 0.2973
Epoch 29/100
30/30 [==============================] - 5s 176ms/step - total_loss: 0.1706 - cls_loss: 0.0753 - box_loss: 8.0214e-04 - model_loss: 0.1155 - val_total_loss: 0.3587 - val_cls_loss: 0.2341 - val_box_loss: 0.0014 - val_model_loss: 0.3036
Epoch 30/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.1683 - cls_loss: 0.0783 - box_loss: 6.9788e-04 - model_loss: 0.1132 - val_total_loss: 0.3515 - val_cls_loss: 0.2311 - val_box_loss: 0.0013 - val_model_loss: 0.2964
Epoch 31/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.1615 - cls_loss: 0.0685 - box_loss: 7.5762e-04 - model_loss: 0.1064 - val_total_loss: 0.3618 - val_cls_loss: 0.2374 - val_box_loss: 0.0014 - val_model_loss: 0.3067
Epoch 32/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.1568 - cls_loss: 0.0537 - box_loss: 9.6010e-04 - model_loss: 0.1017 - val_total_loss: 0.3441 - val_cls_loss: 0.2237 - val_box_loss: 0.0013 - val_model_loss: 0.2889
Epoch 33/100
30/30 [==============================] - 6s 190ms/step - total_loss: 0.1450 - cls_loss: 0.0562 - box_loss: 6.7395e-04 - model_loss: 0.0899 - val_total_loss: 0.3508 - val_cls_loss: 0.2304 - val_box_loss: 0.0013 - val_model_loss: 0.2957
Epoch 34/100
30/30 [==============================] - 6s 203ms/step - total_loss: 0.1400 - cls_loss: 0.0587 - box_loss: 5.2355e-04 - model_loss: 0.0849 - val_total_loss: 0.3581 - val_cls_loss: 0.2337 - val_box_loss: 0.0014 - val_model_loss: 0.3030
Epoch 35/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1359 - cls_loss: 0.0509 - box_loss: 5.9696e-04 - model_loss: 0.0808 - val_total_loss: 0.3723 - val_cls_loss: 0.2470 - val_box_loss: 0.0014 - val_model_loss: 0.3172
Epoch 36/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1478 - cls_loss: 0.0436 - box_loss: 9.8155e-04 - model_loss: 0.0927 - val_total_loss: 0.3633 - val_cls_loss: 0.2393 - val_box_loss: 0.0014 - val_model_loss: 0.3082
Epoch 37/100
30/30 [==============================] - 6s 196ms/step - total_loss: 0.1221 - cls_loss: 0.0376 - box_loss: 5.8971e-04 - model_loss: 0.0670 - val_total_loss: 0.3657 - val_cls_loss: 0.2446 - val_box_loss: 0.0013 - val_model_loss: 0.3106
Epoch 38/100
30/30 [==============================] - 6s 210ms/step - total_loss: 0.1150 - cls_loss: 0.0345 - box_loss: 5.0973e-04 - model_loss: 0.0599 - val_total_loss: 0.3698 - val_cls_loss: 0.2469 - val_box_loss: 0.0014 - val_model_loss: 0.3147
Epoch 39/100
30/30 [==============================] - 6s 184ms/step - total_loss: 0.1236 - cls_loss: 0.0358 - box_loss: 6.5545e-04 - model_loss: 0.0685 - val_total_loss: 0.3709 - val_cls_loss: 0.2474 - val_box_loss: 0.0014 - val_model_loss: 0.3158
Epoch 40/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.1369 - cls_loss: 0.0365 - box_loss: 9.0680e-04 - model_loss: 0.0818 - val_total_loss: 0.3698 - val_cls_loss: 0.2475 - val_box_loss: 0.0013 - val_model_loss: 0.3147
Epoch 41/100
30/30 [==============================] - 6s 200ms/step - total_loss: 0.1268 - cls_loss: 0.0422 - box_loss: 5.9183e-04 - model_loss: 0.0717 - val_total_loss: 0.3802 - val_cls_loss: 0.2596 - val_box_loss: 0.0013 - val_model_loss: 0.3252
Epoch 42/100
30/30 [==============================] - 5s 169ms/step - total_loss: 0.1141 - cls_loss: 0.0362 - box_loss: 4.5653e-04 - model_loss: 0.0591 - val_total_loss: 0.3801 - val_cls_loss: 0.2600 - val_box_loss: 0.0013 - val_model_loss: 0.3251
Epoch 43/100
30/30 [==============================] - 6s 213ms/step - total_loss: 0.1229 - cls_loss: 0.0412 - box_loss: 5.3317e-04 - model_loss: 0.0679 - val_total_loss: 0.3831 - val_cls_loss: 0.2646 - val_box_loss: 0.0013 - val_model_loss: 0.3281
Epoch 44/100
30/30 [==============================] - 6s 183ms/step - total_loss: 0.1282 - cls_loss: 0.0377 - box_loss: 7.0942e-04 - model_loss: 0.0731 - val_total_loss: 0.4143 - val_cls_loss: 0.2939 - val_box_loss: 0.0013 - val_model_loss: 0.3593
Epoch 45/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.1121 - cls_loss: 0.0323 - box_loss: 4.9546e-04 - model_loss: 0.0570 - val_total_loss: 0.4145 - val_cls_loss: 0.2963 - val_box_loss: 0.0013 - val_model_loss: 0.3595
Epoch 46/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1132 - cls_loss: 0.0367 - box_loss: 4.2932e-04 - model_loss: 0.0582 - val_total_loss: 0.4164 - val_cls_loss: 0.2979 - val_box_loss: 0.0013 - val_model_loss: 0.3614
Epoch 47/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.1073 - cls_loss: 0.0276 - box_loss: 4.9285e-04 - model_loss: 0.0522 - val_total_loss: 0.4117 - val_cls_loss: 0.2921 - val_box_loss: 0.0013 - val_model_loss: 0.3567
Epoch 48/100
30/30 [==============================] - 6s 200ms/step - total_loss: 0.1153 - cls_loss: 0.0361 - box_loss: 4.8306e-04 - model_loss: 0.0603 - val_total_loss: 0.4164 - val_cls_loss: 0.2973 - val_box_loss: 0.0013 - val_model_loss: 0.3614
Epoch 49/100
30/30 [==============================] - 5s 177ms/step - total_loss: 0.1034 - cls_loss: 0.0251 - box_loss: 4.6587e-04 - model_loss: 0.0484 - val_total_loss: 0.4252 - val_cls_loss: 0.3047 - val_box_loss: 0.0013 - val_model_loss: 0.3702
Epoch 50/100
30/30 [==============================] - 6s 208ms/step - total_loss: 0.1059 - cls_loss: 0.0282 - box_loss: 4.5344e-04 - model_loss: 0.0508 - val_total_loss: 0.4087 - val_cls_loss: 0.2913 - val_box_loss: 0.0012 - val_model_loss: 0.3537
Epoch 51/100
30/30 [==============================] - 5s 169ms/step - total_loss: 0.1270 - cls_loss: 0.0375 - box_loss: 6.9003e-04 - model_loss: 0.0720 - val_total_loss: 0.3905 - val_cls_loss: 0.2727 - val_box_loss: 0.0013 - val_model_loss: 0.3355
Epoch 52/100
30/30 [==============================] - 6s 207ms/step - total_loss: 0.1051 - cls_loss: 0.0278 - box_loss: 4.4440e-04 - model_loss: 0.0501 - val_total_loss: 0.4038 - val_cls_loss: 0.2828 - val_box_loss: 0.0013 - val_model_loss: 0.3488
Epoch 53/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1089 - cls_loss: 0.0251 - box_loss: 5.7645e-04 - model_loss: 0.0539 - val_total_loss: 0.4134 - val_cls_loss: 0.2921 - val_box_loss: 0.0013 - val_model_loss: 0.3584
Epoch 54/100
30/30 [==============================] - 6s 211ms/step - total_loss: 0.1325 - cls_loss: 0.0270 - box_loss: 0.0010 - model_loss: 0.0775 - val_total_loss: 0.4376 - val_cls_loss: 0.3080 - val_box_loss: 0.0015 - val_model_loss: 0.3826
Epoch 55/100
30/30 [==============================] - 6s 198ms/step - total_loss: 0.1220 - cls_loss: 0.0314 - box_loss: 7.1229e-04 - model_loss: 0.0670 - val_total_loss: 0.4177 - val_cls_loss: 0.2935 - val_box_loss: 0.0014 - val_model_loss: 0.3627
Epoch 56/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.1226 - cls_loss: 0.0370 - box_loss: 6.1162e-04 - model_loss: 0.0676 - val_total_loss: 0.4244 - val_cls_loss: 0.3003 - val_box_loss: 0.0014 - val_model_loss: 0.3694
Epoch 57/100
30/30 [==============================] - 6s 201ms/step - total_loss: 0.1268 - cls_loss: 0.0327 - box_loss: 7.8454e-04 - model_loss: 0.0719 - val_total_loss: 0.4210 - val_cls_loss: 0.2944 - val_box_loss: 0.0014 - val_model_loss: 0.3661
Epoch 58/100
30/30 [==============================] - 6s 193ms/step - total_loss: 0.1200 - cls_loss: 0.0247 - box_loss: 8.0744e-04 - model_loss: 0.0651 - val_total_loss: 0.4291 - val_cls_loss: 0.2992 - val_box_loss: 0.0015 - val_model_loss: 0.3741
Epoch 59/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.1347 - cls_loss: 0.0315 - box_loss: 9.6482e-04 - model_loss: 0.0797 - val_total_loss: 0.4318 - val_cls_loss: 0.3055 - val_box_loss: 0.0014 - val_model_loss: 0.3769
Epoch 60/100
30/30 [==============================] - 6s 204ms/step - total_loss: 0.1175 - cls_loss: 0.0228 - box_loss: 7.9551e-04 - model_loss: 0.0625 - val_total_loss: 0.4222 - val_cls_loss: 0.3009 - val_box_loss: 0.0013 - val_model_loss: 0.3673
Epoch 61/100
30/30 [==============================] - 5s 171ms/step - total_loss: 0.1253 - cls_loss: 0.0336 - box_loss: 7.3396e-04 - model_loss: 0.0703 - val_total_loss: 0.4221 - val_cls_loss: 0.3044 - val_box_loss: 0.0013 - val_model_loss: 0.3672
Epoch 62/100
30/30 [==============================] - 5s 171ms/step - total_loss: 0.1357 - cls_loss: 0.0332 - box_loss: 9.5000e-04 - model_loss: 0.0807 - val_total_loss: 0.4078 - val_cls_loss: 0.2856 - val_box_loss: 0.0013 - val_model_loss: 0.3529
Epoch 63/100
30/30 [==============================] - 6s 188ms/step - total_loss: 0.1301 - cls_loss: 0.0278 - box_loss: 9.4730e-04 - model_loss: 0.0752 - val_total_loss: 0.4084 - val_cls_loss: 0.2850 - val_box_loss: 0.0014 - val_model_loss: 0.3535
Epoch 64/100
30/30 [==============================] - 6s 194ms/step - total_loss: 0.1176 - cls_loss: 0.0258 - box_loss: 7.3795e-04 - model_loss: 0.0627 - val_total_loss: 0.4209 - val_cls_loss: 0.2949 - val_box_loss: 0.0014 - val_model_loss: 0.3660
Epoch 65/100
30/30 [==============================] - 7s 214ms/step - total_loss: 0.0941 - cls_loss: 0.0183 - box_loss: 4.1812e-04 - model_loss: 0.0392 - val_total_loss: 0.4439 - val_cls_loss: 0.3164 - val_box_loss: 0.0015 - val_model_loss: 0.3890
Epoch 66/100
30/30 [==============================] - 7s 214ms/step - total_loss: 0.1001 - cls_loss: 0.0215 - box_loss: 4.7330e-04 - model_loss: 0.0452 - val_total_loss: 0.4528 - val_cls_loss: 0.3231 - val_box_loss: 0.0015 - val_model_loss: 0.3979
Epoch 67/100
30/30 [==============================] - 6s 205ms/step - total_loss: 0.0969 - cls_loss: 0.0201 - box_loss: 4.3725e-04 - model_loss: 0.0419 - val_total_loss: 0.4511 - val_cls_loss: 0.3262 - val_box_loss: 0.0014 - val_model_loss: 0.3962
Epoch 68/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1109 - cls_loss: 0.0300 - box_loss: 5.1976e-04 - model_loss: 0.0560 - val_total_loss: 0.4423 - val_cls_loss: 0.3137 - val_box_loss: 0.0015 - val_model_loss: 0.3874
Epoch 69/100
30/30 [==============================] - 5s 178ms/step - total_loss: 0.1259 - cls_loss: 0.0408 - box_loss: 6.0400e-04 - model_loss: 0.0710 - val_total_loss: 0.4344 - val_cls_loss: 0.3124 - val_box_loss: 0.0013 - val_model_loss: 0.3795
Epoch 70/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.0959 - cls_loss: 0.0193 - box_loss: 4.3317e-04 - model_loss: 0.0410 - val_total_loss: 0.4373 - val_cls_loss: 0.3190 - val_box_loss: 0.0013 - val_model_loss: 0.3824
Epoch 71/100
30/30 [==============================] - 6s 194ms/step - total_loss: 0.0959 - cls_loss: 0.0186 - box_loss: 4.4751e-04 - model_loss: 0.0410 - val_total_loss: 0.4540 - val_cls_loss: 0.3352 - val_box_loss: 0.0013 - val_model_loss: 0.3991
Epoch 72/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.1016 - cls_loss: 0.0191 - box_loss: 5.5197e-04 - model_loss: 0.0467 - val_total_loss: 0.4385 - val_cls_loss: 0.3216 - val_box_loss: 0.0012 - val_model_loss: 0.3836
Epoch 73/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1186 - cls_loss: 0.0295 - box_loss: 6.8361e-04 - model_loss: 0.0637 - val_total_loss: 0.4404 - val_cls_loss: 0.3198 - val_box_loss: 0.0013 - val_model_loss: 0.3855
Epoch 74/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1171 - cls_loss: 0.0261 - box_loss: 7.2368e-04 - model_loss: 0.0623 - val_total_loss: 0.4599 - val_cls_loss: 0.3378 - val_box_loss: 0.0013 - val_model_loss: 0.4050
Epoch 75/100
30/30 [==============================] - 6s 191ms/step - total_loss: 0.1011 - cls_loss: 0.0151 - box_loss: 6.2282e-04 - model_loss: 0.0463 - val_total_loss: 0.4596 - val_cls_loss: 0.3351 - val_box_loss: 0.0014 - val_model_loss: 0.4048
Epoch 76/100
30/30 [==============================] - 6s 185ms/step - total_loss: 0.0905 - cls_loss: 0.0164 - box_loss: 3.8389e-04 - model_loss: 0.0356 - val_total_loss: 0.4861 - val_cls_loss: 0.3605 - val_box_loss: 0.0014 - val_model_loss: 0.4313
Epoch 77/100
30/30 [==============================] - 6s 209ms/step - total_loss: 0.1114 - cls_loss: 0.0264 - box_loss: 6.0414e-04 - model_loss: 0.0566 - val_total_loss: 0.4776 - val_cls_loss: 0.3508 - val_box_loss: 0.0014 - val_model_loss: 0.4228
Epoch 78/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.0958 - cls_loss: 0.0138 - box_loss: 5.4198e-04 - model_loss: 0.0409 - val_total_loss: 0.4794 - val_cls_loss: 0.3509 - val_box_loss: 0.0015 - val_model_loss: 0.4246
Epoch 79/100
30/30 [==============================] - 5s 174ms/step - total_loss: 0.1001 - cls_loss: 0.0177 - box_loss: 5.5167e-04 - model_loss: 0.0452 - val_total_loss: 0.4825 - val_cls_loss: 0.3575 - val_box_loss: 0.0014 - val_model_loss: 0.4277
Epoch 80/100
30/30 [==============================] - 6s 186ms/step - total_loss: 0.1118 - cls_loss: 0.0280 - box_loss: 5.8003e-04 - model_loss: 0.0570 - val_total_loss: 0.4675 - val_cls_loss: 0.3453 - val_box_loss: 0.0013 - val_model_loss: 0.4127
Epoch 81/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.0891 - cls_loss: 0.0109 - box_loss: 4.6892e-04 - model_loss: 0.0343 - val_total_loss: 0.4521 - val_cls_loss: 0.3339 - val_box_loss: 0.0013 - val_model_loss: 0.3972
Epoch 82/100
30/30 [==============================] - 5s 177ms/step - total_loss: 0.1048 - cls_loss: 0.0209 - box_loss: 5.8195e-04 - model_loss: 0.0500 - val_total_loss: 0.4535 - val_cls_loss: 0.3352 - val_box_loss: 0.0013 - val_model_loss: 0.3987
Epoch 83/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.1186 - cls_loss: 0.0267 - box_loss: 7.4208e-04 - model_loss: 0.0638 - val_total_loss: 0.4401 - val_cls_loss: 0.3200 - val_box_loss: 0.0013 - val_model_loss: 0.3853
Epoch 84/100
30/30 [==============================] - 6s 184ms/step - total_loss: 0.1037 - cls_loss: 0.0148 - box_loss: 6.8151e-04 - model_loss: 0.0489 - val_total_loss: 0.4640 - val_cls_loss: 0.3401 - val_box_loss: 0.0014 - val_model_loss: 0.4092
Epoch 85/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.1100 - cls_loss: 0.0239 - box_loss: 6.2668e-04 - model_loss: 0.0552 - val_total_loss: 0.4728 - val_cls_loss: 0.3497 - val_box_loss: 0.0014 - val_model_loss: 0.4180
Epoch 86/100
30/30 [==============================] - 6s 203ms/step - total_loss: 0.0926 - cls_loss: 0.0169 - box_loss: 4.1826e-04 - model_loss: 0.0378 - val_total_loss: 0.4905 - val_cls_loss: 0.3678 - val_box_loss: 0.0014 - val_model_loss: 0.4357
Epoch 87/100
30/30 [==============================] - 6s 203ms/step - total_loss: 0.0854 - cls_loss: 0.0147 - box_loss: 3.1862e-04 - model_loss: 0.0306 - val_total_loss: 0.4375 - val_cls_loss: 0.3151 - val_box_loss: 0.0014 - val_model_loss: 0.3827
Epoch 88/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.0903 - cls_loss: 0.0165 - box_loss: 3.8001e-04 - model_loss: 0.0355 - val_total_loss: 0.4681 - val_cls_loss: 0.3383 - val_box_loss: 0.0015 - val_model_loss: 0.4133
Epoch 89/100
30/30 [==============================] - 6s 204ms/step - total_loss: 0.0956 - cls_loss: 0.0209 - box_loss: 3.9925e-04 - model_loss: 0.0408 - val_total_loss: 0.4716 - val_cls_loss: 0.3471 - val_box_loss: 0.0014 - val_model_loss: 0.4169
Epoch 90/100
30/30 [==============================] - 6s 206ms/step - total_loss: 0.0940 - cls_loss: 0.0182 - box_loss: 4.2096e-04 - model_loss: 0.0393 - val_total_loss: 0.4583 - val_cls_loss: 0.3342 - val_box_loss: 0.0014 - val_model_loss: 0.4035
Epoch 91/100
30/30 [==============================] - 6s 210ms/step - total_loss: 0.0909 - cls_loss: 0.0123 - box_loss: 4.7623e-04 - model_loss: 0.0361 - val_total_loss: 0.4585 - val_cls_loss: 0.3349 - val_box_loss: 0.0014 - val_model_loss: 0.4037
Epoch 92/100
30/30 [==============================] - 6s 181ms/step - total_loss: 0.0949 - cls_loss: 0.0115 - box_loss: 5.7280e-04 - model_loss: 0.0402 - val_total_loss: 0.4616 - val_cls_loss: 0.3369 - val_box_loss: 0.0014 - val_model_loss: 0.4069
Epoch 93/100
30/30 [==============================] - 5s 175ms/step - total_loss: 0.1141 - cls_loss: 0.0263 - box_loss: 6.6052e-04 - model_loss: 0.0593 - val_total_loss: 0.4672 - val_cls_loss: 0.3369 - val_box_loss: 0.0015 - val_model_loss: 0.4124
Epoch 94/100
30/30 [==============================] - 6s 210ms/step - total_loss: 0.1126 - cls_loss: 0.0160 - box_loss: 8.3728e-04 - model_loss: 0.0579 - val_total_loss: 0.4634 - val_cls_loss: 0.3342 - val_box_loss: 0.0015 - val_model_loss: 0.4087
Epoch 95/100
30/30 [==============================] - 6s 209ms/step - total_loss: 0.0937 - cls_loss: 0.0155 - box_loss: 4.7037e-04 - model_loss: 0.0390 - val_total_loss: 0.4526 - val_cls_loss: 0.3252 - val_box_loss: 0.0015 - val_model_loss: 0.3979
Epoch 96/100
30/30 [==============================] - 5s 172ms/step - total_loss: 0.0838 - cls_loss: 0.0101 - box_loss: 3.7900e-04 - model_loss: 0.0290 - val_total_loss: 0.4674 - val_cls_loss: 0.3381 - val_box_loss: 0.0015 - val_model_loss: 0.4127
Epoch 97/100
30/30 [==============================] - 6s 202ms/step - total_loss: 0.1081 - cls_loss: 0.0171 - box_loss: 7.2588e-04 - model_loss: 0.0534 - val_total_loss: 0.4780 - val_cls_loss: 0.3481 - val_box_loss: 0.0015 - val_model_loss: 0.4233
Epoch 98/100
30/30 [==============================] - 5s 170ms/step - total_loss: 0.0818 - cls_loss: 0.0094 - box_loss: 3.5368e-04 - model_loss: 0.0271 - val_total_loss: 0.4714 - val_cls_loss: 0.3459 - val_box_loss: 0.0014 - val_model_loss: 0.4167
Epoch 99/100
30/30 [==============================] - 5s 168ms/step - total_loss: 0.0778 - cls_loss: 0.0082 - box_loss: 2.9762e-04 - model_loss: 0.0231 - val_total_loss: 0.4700 - val_cls_loss: 0.3445 - val_box_loss: 0.0014 - val_model_loss: 0.4153
Epoch 100/100
30/30 [==============================] - 5s 173ms/step - total_loss: 0.0788 - cls_loss: 0.0074 - box_loss: 3.3287e-04 - model_loss: 0.0241 - val_total_loss: 0.4701 - val_cls_loss: 0.3474 - val_box_loss: 0.0014 - val_model_loss: 0.4154
&quot;&quot;&quot;

pattern = r&quot;total_loss: (\d+\.\d+(?:e[+-]?\d+)?) - cls_loss: (\d+\.\d+(?:e[+-]?\d+)?) - box_loss: (\d+\.\d+(?:e[+-]?\d+)?) - model_loss: (\d+\.\d+(?:e[+-]?\d+)?) - val_total_loss: (\d+\.\d+(?:e[+-]?\d+)?) - val_cls_loss: (\d+\.\d+(?:e[+-]?\d+)?) - val_box_loss: (\d+\.\d+(?:e[+-]?\d+)?) - val_model_loss: (\d+\.\d+(?:e[+-]?\d+)?)&quot;

matches = re.findall(pattern, txt_file)
# Convert the matched strings to float and separate them into lists
total_losses, cls_losses, box_losses, model_losses, val_total_losses, val_cls_losses, val_box_losses, val_model_losses = zip(*((float(total), float(cls), float(box), float(model), float(val_total), float(val_cls), float(val_box), float(val_model))
                                                           for total, cls, box, model,val_total, val_cls, val_box, val_model in matches))

epochs = range(1, len(total_losses) + 1)

plt.figure(figsize=(9,9))
plt.plot(epochs, total_losses, (&#39;#D71939&#39;), label=&quot;Total Loss&quot;, linewidth=4)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;Total Loss&quot;)
plt.legend()
plt.subplot(4, 2, 2)
plt.plot(epochs, cls_losses, (&#39;#D71939&#39;), label=&quot;Classification Loss&quot;,linewidth=4)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;Classification Loss&quot;)
plt.legend()

plt.subplot(4, 2, 3)
plt.plot(epochs, box_losses, (&#39;#D71939&#39;), label=&quot;Box Loss&quot;,linewidth=4)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;Box Loss&quot;)
plt.legend()

plt.subplot(4, 2, 4)
plt.plot(epochs, model_losses, (&#39;#D71939&#39;), label=&quot;Model Loss&quot;,linewidth=4)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;Model Loss&quot;)
plt.legend()

plt.subplot(4, 2, 5)
plt.plot(epochs, val_total_losses, (&#39;#D71939&#39;), label=&quot;Validation Total Loss&quot;,linewidth=4)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;Validation Total Loss&quot;)
plt.legend()

plt.subplot(4, 2, 6)
plt.plot(epochs, val_cls_losses, (&#39;#D71939&#39;), label=&quot;Validation Classification Loss&quot;,linewidth=4)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;Validation Classification Loss&quot;)
plt.legend()

plt.subplot(4, 2, 7)
plt.plot(epochs, val_box_losses, (&#39;#D71939&#39;), label=&quot;Validation Box Loss&quot;,linewidth=4)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;Validation Box Loss&quot;)
plt.legend()
plt.subplot(4, 2, 8)
plt.plot(epochs, val_model_losses, (&#39;#D71939&#39;), label=&quot;Validation Model Loss&quot;,linewidth=4)
plt.xlabel(&quot;Epochs&quot;)
plt.ylabel(&quot;Validation Model Loss&quot;)
plt.legend()
plt.show()
plt.tight_layout()
plt.show()
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
C:\Users\aditi\AppData\Local\Temp\ipykernel_48100\310583337.py:218: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.
  plt.subplot(4, 2, 2)
</pre></div></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Custom_training_bolt_detection_10_1.png" src="../_images/notebooks_Custom_training_bolt_detection_10_1.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
&lt;Figure size 640x480 with 0 Axes&gt;
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>import matplotlib.pyplot as plt
import numpy as np

# Given data
metrics = {
    &#39;AP&#39;: [0.712, 0.940, 0.898, 0.057, 0.800, 0.778],
    &#39;AR&#39;: [0.331, 0.762, 0.762, 0.200, 0.800, 0.822]
}
categories = [&#39;IoU=0.50:0.95, all&#39;, &#39;IoU=0.50, all&#39;, &#39;IoU=0.75, all&#39;,
              &#39;IoU=0.50:0.95, small&#39;, &#39;IoU=0.50:0.95, medium&#39;, &#39;IoU=0.50:0.95, large&#39;]

# Set up the matplotlib figure
bar_width = 0.35  # the width of the bars
index = np.arange(len(metrics[&#39;AP&#39;]))  # the label locations

fig, ax1 = plt.subplots(figsize=(16,13))

# Bar plots
rects1 = ax1.bar(index - bar_width/2, metrics[&#39;AP&#39;], bar_width, label=&#39;Average Precision (AP)&#39;, color=&#39;#DB2E4B&#39;) # noqa
rects2 = ax1.bar(index + bar_width/2, metrics[&#39;AR&#39;], bar_width, label=&#39;Average Recall (AR)&#39;, color=&#39;#FFF572&#39;) # noqa


# Labels and legends
ax1.set_xlabel(&#39;IoU Thresholds and Categories&#39;,fontsize=16)
ax1.set_ylabel(&#39; Metric value&#39;,fontsize=16)
ax1.set_title(&#39;Average Precision, Average Recall per Category(Bolt)&#39;,fontsize=20)

# Adjust tick label size (new)
ax1.tick_params(axis=&#39;x&#39;, labelsize=14)
ax1.tick_params(axis=&#39;y&#39;, labelsize=14)

ax1.set_xticks(index)
ax1.set_xticklabels(categories, rotation=45, fontsize=12)

ax1.legend(loc=&#39;upper left&#39;,fontsize = &#39;large&#39;)
plt.savefig(&#39;barplot.png&#39;)
#plt.show()
<br/></pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/notebooks_Custom_training_bolt_detection_11_0.png" src="../_images/notebooks_Custom_training_bolt_detection_11_0.png" />
</div>
</div>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          <a class="prev-page" href="People-detection.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Using RoboFlow dataset to detect people using MediaPipe</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2024, kromium.no
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Using a custom made dataset to detect bolts using Mediapipe</a><ul>
<li><a class="reference internal" href="#Creating-the-steps-for-training">Creating the steps for training</a></li>
<li><a class="reference internal" href="#Loading-the-data,-and-training">Loading the data, and training</a></li>
<li><a class="reference internal" href="#Evaluating-the-model">Evaluating the model</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script src="../_static/documentation_options.js?v=51b770b3"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/scripts/furo.js?v=4e2eecee"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>